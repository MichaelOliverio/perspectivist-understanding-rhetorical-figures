{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per aprire i file in una directory e ordinarli\n",
    "def open_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_sig(x, sig=3):\n",
    "    if isinstance(x, (float, int)):\n",
    "        return float(f\"{x:.{sig}g}\")\n",
    "    return x\n",
    "\n",
    "def format_report(report_dict):\n",
    "    rounded = {}\n",
    "    for label, metrics in report_dict.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            rounded[label] = {k: round_sig(v) for k, v in metrics.items()}\n",
    "        else:\n",
    "            rounded[label] = round_sig(metrics)\n",
    "    return rounded\n",
    "\n",
    "def print_formatted_report(report_dict):\n",
    "    print(\"\\nðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\")\n",
    "    labels = [label for label in report_dict if label not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "    header = f\"{'Label':<20} {'Prec':>8} {'Rec':>8} {'F1':>8} {'Support':>8}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for label in labels + ['macro avg', 'weighted avg']:\n",
    "        row = report_dict[label]\n",
    "        print(f\"{label:<20} {row['precision']:>8.3f} {row['recall']:>8.3f} {row['f1-score']:>8.3f} {row['support']:>8.0f}\")\n",
    "    print(f\"{'Accuracy':<20} {'':>8} {'':>8} {'':>8} {report_dict['accuracy']:>8.3f}\")\n",
    "\n",
    "def calculate_metrics(df, print_confusion=False):\n",
    "    # Assumiamo che prediction e actual siano le colonne corrette\n",
    "    df['extracted_prediction'] = df['prediction'].astype(str)\n",
    "    df['rhetorical_figure'] = df['actual'].astype(str)  # assicurati che 'actual' sia la colonna giusta\n",
    "    \n",
    "    # Rimuoviamo eventuali righe con valori mancanti nelle due colonne (evita errori)\n",
    "    df_clean = df\n",
    "\n",
    "    if print_confusion:\n",
    "        print(f\"\\nðŸ§© Matrice di confusione:\")\n",
    "        confusion = pd.crosstab(df_clean['rhetorical_figure'], df_clean['extracted_prediction'],\n",
    "                                rownames=['Actual'], colnames=['Predicted'])\n",
    "        print(confusion)\n",
    "\n",
    "    report = classification_report(df_clean['rhetorical_figure'], df_clean['extracted_prediction'], output_dict=True, zero_division=0)\n",
    "    return report\n",
    "\n",
    "def average_reports(reports):\n",
    "    avg_report = {}\n",
    "    keys = reports[0].keys()\n",
    "\n",
    "    for key in keys:\n",
    "        if isinstance(reports[0][key], dict):\n",
    "            avg_report[key] = {}\n",
    "            for metric in reports[0][key]:\n",
    "                values = [r[key].get(metric, 0.0) for r in reports if key in r]\n",
    "                avg_report[key][metric] = np.mean(values)\n",
    "        else:  # accuracy\n",
    "            values = [r.get(key, 0.0) for r in reports]\n",
    "            avg_report[key] = np.mean(values)\n",
    "\n",
    "    return avg_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.308    0.414    0.353       29\n",
      "CONTEXT SHIFT           0.356    0.232    0.281       69\n",
      "EUPHEMISM               0.167    0.111    0.133        9\n",
      "FALSE ASSERTION         0.143    0.062    0.087       16\n",
      "HYPERBOLE               0.600    0.214    0.316       14\n",
      "OTHER                   0.273    0.257    0.265       35\n",
      "OXYMORON                0.022    0.333    0.041        3\n",
      "RHETORICAL QUESTION     0.450    0.346    0.391       26\n",
      "macro avg               0.290    0.246    0.233      201\n",
      "weighted avg            0.333    0.259    0.279      201\n",
      "Accuracy                                           0.259\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.256    0.294    0.274       34\n",
      "CONTEXT SHIFT           0.356    0.195    0.252       82\n",
      "EUPHEMISM               0.167    0.030    0.051       33\n",
      "FALSE ASSERTION         0.000    0.000    0.000       10\n",
      "HYPERBOLE               0.400    0.250    0.308        8\n",
      "OTHER                   0.061    0.100    0.075       20\n",
      "OXYMORON                0.022    1.000    0.043        1\n",
      "RHETORICAL QUESTION     0.200    0.308    0.242       13\n",
      "macro avg               0.183    0.272    0.156      201\n",
      "weighted avg            0.251    0.179    0.193      201\n",
      "Accuracy                                           0.179\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.282    0.393    0.328       28\n",
      "CONTEXT SHIFT           0.178    0.235    0.203       34\n",
      "EUPHEMISM               0.167    0.167    0.167        6\n",
      "FALSE ASSERTION         0.286    0.062    0.103       32\n",
      "HYPERBOLE               0.400    0.095    0.154       21\n",
      "OTHER                   0.273    0.164    0.205       55\n",
      "OXYMORON                0.022    0.200    0.039        5\n",
      "RHETORICAL QUESTION     0.300    0.300    0.300       20\n",
      "macro avg               0.238    0.202    0.187      201\n",
      "weighted avg            0.267    0.199    0.204      201\n",
      "Accuracy                                           0.199\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.433    0.377       30\n",
      "CONTEXT SHIFT           0.378    0.354    0.366       48\n",
      "EUPHEMISM               0.000    0.000    0.000       16\n",
      "FALSE ASSERTION         0.143    0.026    0.044       38\n",
      "HYPERBOLE               0.400    0.095    0.154       21\n",
      "OTHER                   0.273    0.321    0.295       28\n",
      "OXYMORON                0.022    0.250    0.040        4\n",
      "RHETORICAL QUESTION     0.350    0.438    0.389       16\n",
      "macro avg               0.237    0.240    0.208      201\n",
      "weighted avg            0.275    0.249    0.241      201\n",
      "Accuracy                                           0.249\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.179    0.368    0.241       19\n",
      "CONTEXT SHIFT           0.200    0.225    0.212       40\n",
      "EUPHEMISM               0.167    0.071    0.100       14\n",
      "FALSE ASSERTION         0.286    0.074    0.118       27\n",
      "HYPERBOLE               0.600    0.136    0.222       22\n",
      "OTHER                   0.333    0.250    0.286       44\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.400    0.242    0.302       33\n",
      "macro avg               0.271    0.171    0.185      201\n",
      "weighted avg            0.311    0.204    0.224      201\n",
      "Accuracy                                           0.204\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.154    0.200    0.174       30\n",
      "CONTEXT SHIFT           0.133    0.273    0.179       22\n",
      "EUPHEMISM               0.167    0.048    0.074       21\n",
      "FALSE ASSERTION         0.143    0.032    0.053       31\n",
      "HYPERBOLE               0.600    0.111    0.188       27\n",
      "OTHER                   0.303    0.244    0.270       41\n",
      "OXYMORON                0.000    0.000    0.000        3\n",
      "RHETORICAL QUESTION     0.400    0.308    0.348       26\n",
      "macro avg               0.237    0.152    0.161      201\n",
      "weighted avg            0.271    0.174    0.187      201\n",
      "Accuracy                                           0.174\n",
      "Processing model: Llama-3.1-8B-Instruct_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.211    0.276    0.239       29\n",
      "CONTEXT SHIFT           0.389    0.203    0.267       69\n",
      "EUPHEMISM               0.250    0.333    0.286        9\n",
      "FALSE ASSERTION         0.100    0.062    0.077       16\n",
      "HYPERBOLE               0.286    0.143    0.190       14\n",
      "OTHER                   0.000    0.000    0.000       35\n",
      "OXYMORON                0.000    0.000    0.000        3\n",
      "RHETORICAL QUESTION     0.254    0.577    0.353       26\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.165    0.177    0.157      201\n",
      "weighted avg            0.236    0.214    0.204      201\n",
      "Accuracy                                           0.214\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.263    0.294    0.278       34\n",
      "CONTEXT SHIFT           0.444    0.195    0.271       82\n",
      "EUPHEMISM               0.333    0.121    0.178       33\n",
      "FALSE ASSERTION         0.100    0.100    0.100       10\n",
      "HYPERBOLE               0.286    0.250    0.267        8\n",
      "OTHER                   0.000    0.000    0.000       20\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.119    0.538    0.194       13\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.172    0.167    0.143      201\n",
      "weighted avg            0.305    0.199    0.215      201\n",
      "Accuracy                                           0.199\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.316    0.429    0.364       28\n",
      "CONTEXT SHIFT           0.111    0.118    0.114       34\n",
      "EUPHEMISM               0.250    0.500    0.333        6\n",
      "FALSE ASSERTION         0.400    0.125    0.190       32\n",
      "HYPERBOLE               0.286    0.095    0.143       21\n",
      "OTHER                   0.000    0.000    0.000       55\n",
      "OXYMORON                0.040    0.200    0.067        5\n",
      "RHETORICAL QUESTION     0.220    0.650    0.329       20\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.180    0.235    0.171      201\n",
      "weighted avg            0.187    0.194    0.160      201\n",
      "Accuracy                                           0.194\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.211    0.267    0.235       30\n",
      "CONTEXT SHIFT           0.250    0.188    0.214       48\n",
      "EUPHEMISM               0.083    0.062    0.071       16\n",
      "FALSE ASSERTION         0.100    0.026    0.042       38\n",
      "HYPERBOLE               0.286    0.095    0.143       21\n",
      "OTHER                   0.000    0.000    0.000       28\n",
      "OXYMORON                0.000    0.000    0.000        4\n",
      "RHETORICAL QUESTION     0.186    0.688    0.293       16\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.124    0.147    0.111      201\n",
      "weighted avg            0.161    0.159    0.138      201\n",
      "Accuracy                                           0.159\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.211    0.421    0.281       19\n",
      "CONTEXT SHIFT           0.194    0.175    0.184       40\n",
      "EUPHEMISM               0.250    0.214    0.231       14\n",
      "FALSE ASSERTION         0.400    0.148    0.216       27\n",
      "HYPERBOLE               0.286    0.091    0.138       22\n",
      "OTHER                   0.000    0.000    0.000       44\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.339    0.606    0.435       33\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.187    0.184    0.165      201\n",
      "weighted avg            0.217    0.219    0.195      201\n",
      "Accuracy                                           0.219\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.289    0.367    0.324       30\n",
      "CONTEXT SHIFT           0.111    0.182    0.138       22\n",
      "EUPHEMISM               0.250    0.143    0.182       21\n",
      "FALSE ASSERTION         0.300    0.097    0.146       31\n",
      "HYPERBOLE               0.429    0.111    0.176       27\n",
      "OTHER                   0.000    0.000    0.000       41\n",
      "OXYMORON                0.000    0.000    0.000        3\n",
      "RHETORICAL QUESTION     0.271    0.615    0.376       26\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.183    0.168    0.149      201\n",
      "weighted avg            0.220    0.199    0.177      201\n",
      "Accuracy                                           0.199\n",
      "Processing model: Minerva-7B-instruct-v1.0_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.286    0.207    0.240       29\n",
      "CONTEXT SHIFT           0.382    0.377    0.380       69\n",
      "EUPHEMISM               0.000    0.000    0.000        9\n",
      "FALSE ASSERTION         0.158    0.188    0.171       16\n",
      "HYPERBOLE               0.000    0.000    0.000       14\n",
      "OTHER                   0.500    0.029    0.054       35\n",
      "OXYMORON                0.017    0.333    0.032        3\n",
      "RHETORICAL QUESTION     0.250    0.231    0.240       26\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.177    0.152    0.124      201\n",
      "weighted avg            0.305    0.214    0.220      201\n",
      "Accuracy                                           0.214\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.524    0.324    0.400       34\n",
      "CONTEXT SHIFT           0.456    0.378    0.413       82\n",
      "EUPHEMISM               0.500    0.030    0.057       33\n",
      "FALSE ASSERTION         0.053    0.100    0.069       10\n",
      "HYPERBOLE               0.000    0.000    0.000        8\n",
      "OTHER                   0.000    0.000    0.000       20\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.125    0.231    0.162       13\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.184    0.118    0.122      201\n",
      "weighted avg            0.367    0.234    0.260      201\n",
      "Accuracy                                           0.234\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.381    0.286    0.327       28\n",
      "CONTEXT SHIFT           0.206    0.412    0.275       34\n",
      "EUPHEMISM               0.000    0.000    0.000        6\n",
      "FALSE ASSERTION         0.263    0.156    0.196       32\n",
      "HYPERBOLE               0.000    0.000    0.000       21\n",
      "OTHER                   0.500    0.018    0.035       55\n",
      "OXYMORON                0.034    0.400    0.062        5\n",
      "RHETORICAL QUESTION     0.292    0.350    0.318       20\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.186    0.180    0.135      201\n",
      "weighted avg            0.296    0.184    0.166      201\n",
      "Accuracy                                           0.184\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.381    0.267    0.314       30\n",
      "CONTEXT SHIFT           0.265    0.375    0.310       48\n",
      "EUPHEMISM               0.000    0.000    0.000       16\n",
      "FALSE ASSERTION         0.105    0.053    0.070       38\n",
      "HYPERBOLE               0.200    0.048    0.077       21\n",
      "OTHER                   0.000    0.000    0.000       28\n",
      "OXYMORON                0.034    0.500    0.064        4\n",
      "RHETORICAL QUESTION     0.250    0.375    0.300       16\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.137    0.180    0.126      201\n",
      "weighted avg            0.181    0.184    0.167      201\n",
      "Accuracy                                           0.184\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.429    0.474    0.450       19\n",
      "CONTEXT SHIFT           0.265    0.450    0.333       40\n",
      "EUPHEMISM               0.000    0.000    0.000       14\n",
      "FALSE ASSERTION         0.158    0.111    0.130       27\n",
      "HYPERBOLE               0.200    0.045    0.074       22\n",
      "OTHER                   0.500    0.023    0.043       44\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.417    0.303    0.351       33\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.219    0.156    0.154      201\n",
      "weighted avg            0.314    0.209    0.202      201\n",
      "Accuracy                                           0.209\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.524    0.367    0.431       30\n",
      "CONTEXT SHIFT           0.132    0.409    0.200       22\n",
      "EUPHEMISM               0.000    0.000    0.000       21\n",
      "FALSE ASSERTION         0.158    0.097    0.120       31\n",
      "HYPERBOLE               0.400    0.074    0.125       27\n",
      "OTHER                   0.500    0.024    0.046       41\n",
      "OXYMORON                0.017    0.333    0.032        3\n",
      "RHETORICAL QUESTION     0.417    0.385    0.400       26\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.239    0.188    0.151      201\n",
      "weighted avg            0.327    0.184    0.183      201\n",
      "Accuracy                                           0.184\n",
      "Processing model: Ministral-8B-Instruct-2410_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.310    0.321       29\n",
      "CONTEXT SHIFT           0.315    0.246    0.276       69\n",
      "EUPHEMISM               0.200    0.111    0.143        9\n",
      "FALSE ASSERTION         0.136    0.188    0.158       16\n",
      "HYPERBOLE               0.500    0.071    0.125       14\n",
      "OTHER                   0.400    0.171    0.240       35\n",
      "OXYMORON                0.022    0.333    0.042        3\n",
      "RHETORICAL QUESTION     0.355    0.423    0.386       26\n",
      "macro avg               0.283    0.232    0.211      201\n",
      "weighted avg            0.327    0.244    0.261      201\n",
      "Accuracy                                           0.244\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.370    0.294    0.328       34\n",
      "CONTEXT SHIFT           0.333    0.220    0.265       82\n",
      "EUPHEMISM               0.200    0.030    0.053       33\n",
      "FALSE ASSERTION         0.136    0.300    0.188       10\n",
      "HYPERBOLE               0.000    0.000    0.000        8\n",
      "OTHER                   0.133    0.100    0.114       20\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.097    0.231    0.136       13\n",
      "macro avg               0.159    0.147    0.135      201\n",
      "weighted avg            0.258    0.184    0.202      201\n",
      "Accuracy                                           0.184\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.444    0.429    0.436       28\n",
      "CONTEXT SHIFT           0.204    0.324    0.250       34\n",
      "EUPHEMISM               0.200    0.167    0.182        6\n",
      "FALSE ASSERTION         0.227    0.156    0.185       32\n",
      "HYPERBOLE               0.000    0.000    0.000       21\n",
      "OTHER                   0.400    0.109    0.171       55\n",
      "OXYMORON                0.044    0.400    0.080        5\n",
      "RHETORICAL QUESTION     0.258    0.400    0.314       20\n",
      "macro avg               0.222    0.248    0.202      201\n",
      "weighted avg            0.275    0.224    0.218      201\n",
      "Accuracy                                           0.224\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.370    0.333    0.351       30\n",
      "CONTEXT SHIFT           0.241    0.271    0.255       48\n",
      "EUPHEMISM               0.000    0.000    0.000       16\n",
      "FALSE ASSERTION         0.182    0.105    0.133       38\n",
      "HYPERBOLE               0.000    0.000    0.000       21\n",
      "OTHER                   0.200    0.107    0.140       28\n",
      "OXYMORON                0.022    0.250    0.041        4\n",
      "RHETORICAL QUESTION     0.226    0.438    0.298       16\n",
      "macro avg               0.155    0.188    0.152      201\n",
      "weighted avg            0.193    0.189    0.182      201\n",
      "Accuracy                                           0.189\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.370    0.526    0.435       19\n",
      "CONTEXT SHIFT           0.204    0.275    0.234       40\n",
      "EUPHEMISM               0.200    0.071    0.105       14\n",
      "FALSE ASSERTION         0.227    0.185    0.204       27\n",
      "HYPERBOLE               0.500    0.045    0.083       22\n",
      "OTHER                   0.467    0.159    0.237       44\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.419    0.394    0.406       33\n",
      "macro avg               0.298    0.207    0.213      201\n",
      "weighted avg            0.346    0.239    0.250      201\n",
      "Accuracy                                           0.239\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.407    0.367    0.386       30\n",
      "CONTEXT SHIFT           0.130    0.318    0.184       22\n",
      "EUPHEMISM               0.200    0.048    0.077       21\n",
      "FALSE ASSERTION         0.136    0.097    0.113       31\n",
      "HYPERBOLE               0.000    0.000    0.000       27\n",
      "OTHER                   0.467    0.171    0.250       41\n",
      "OXYMORON                0.022    0.333    0.042        3\n",
      "RHETORICAL QUESTION     0.323    0.385    0.351       26\n",
      "macro avg               0.211    0.215    0.175      201\n",
      "weighted avg            0.254    0.199    0.200      201\n",
      "Accuracy                                           0.199\n",
      "Processing model: Qwen2.5-7B-Instruct_predictions.csv\n",
      "Skipping model 'Qwen2.5-7B-Instruct_predictions.csv' as it contains 'qwen'.\n"
     ]
    }
   ],
   "source": [
    "model_files = open_files('models_generations')\n",
    "actual_files = open_files('actuals')\n",
    "\n",
    "models = {}\n",
    "for model_file in model_files:\n",
    "    # estrai il nome modello rimuovendo pattern specifici\n",
    "    model_name = re.sub(r\"^(fine-tuned-)?|-decoding-\\d+\\.csv$\", \"\", model_file)\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "\n",
    "    if 'qwen' in model_name.lower():\n",
    "        print(f\"Skipping model '{model_name}' as it contains 'qwen'.\")\n",
    "        continue\n",
    "\n",
    "    model = pd.read_csv(os.path.join('models_generations', model_file))\n",
    "\n",
    "    reports = []\n",
    "    for actual_file in actual_files:\n",
    "        actual = pd.read_csv(os.path.join('actuals', actual_file))\n",
    "\n",
    "        # fai il join di actual e model, utilizzando la colonna \"pippo\" di actual e l'index di model\n",
    "        merged = pd.merge(actual, model, left_on='index', right_index=True, how='left')\n",
    "\n",
    "        # save merged output as csv\n",
    "        merged_file = f\"merged_output.csv\"\n",
    "        merged.to_csv(merged_file, index=False)\n",
    "\n",
    "        print(f\"\\nðŸ“Š Report per il modello '{model_name}' con file '{actual_file}':\")\n",
    "        report = calculate_metrics(merged, print_confusion=False)\n",
    "        #print(report)\n",
    "        formatted_report = format_report(report)\n",
    "        print_formatted_report(formatted_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
