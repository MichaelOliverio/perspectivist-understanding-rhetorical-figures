{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per aprire i file in una directory e ordinarli\n",
    "def open_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv\n",
      "Found 0 NaN predictions in LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv for global_actual_labels.csv.\n",
      "Processing model: Llama-3.1-8B-Instruct_predictions.csv\n",
      "Found 14 NaN predictions in Llama-3.1-8B-Instruct_predictions.csv for global_actual_labels.csv.\n",
      "     index             post_id_x            reply_id_x               actual  \\\n",
      "6        6  18184193230015000576   3263700000000000000                OTHER   \n",
      "10      10   8374295896122236928   9960700000000000000      FALSE ASSERTION   \n",
      "19      19   1894119167367809024   9033280000000000000                OTHER   \n",
      "29      29  14374185223286280192  15962200000000000000            HYPERBOLE   \n",
      "68      68  16300389213436499968   7681940000000000000                OTHER   \n",
      "86      86   3037383543302795776   6283640000000000000        CONTEXT SHIFT   \n",
      "88      88   9408805770120683520   2035190000000000000            HYPERBOLE   \n",
      "95      95  11534803039351519232  14401400000000000000                OTHER   \n",
      "115    115  14672930942777870336   4389960000000000000                OTHER   \n",
      "124    124  16379255176565530624  10462000000000000000                OTHER   \n",
      "158    158  17239694814309300224   1239070000000000000                OTHER   \n",
      "169    169    954400581630060800  15189900000000000000  RHETORICAL QUESTION   \n",
      "176    176   6704336624706271232  15276700000000000000              ANALOGY   \n",
      "178    178  15621374748089249792   1864250000000000000  RHETORICAL QUESTION   \n",
      "\n",
      "                post_id_y            reply_id_y  \\\n",
      "6    18184193230015004878   3263697220254276145   \n",
      "10    8374295896122236596   9960698491608353483   \n",
      "19    1894119167367808702   9033282269550186760   \n",
      "29   14374185223286279150  15962231219628500958   \n",
      "68   16300389213436496259   7681944978638246803   \n",
      "86    3037383543302796324   6283644142388211856   \n",
      "88    9408805770120683449   2035191926981981266   \n",
      "95   11534803039351516013  14401413796579297426   \n",
      "115  14672930942777869739   4389956713331137748   \n",
      "124  16379255176565534094  10462018945349578152   \n",
      "158  17239694814309298157   1239066701255211946   \n",
      "169    954400581630060757  15189855149002636496   \n",
      "176   6704336624706271088  15276675242485480973   \n",
      "178  15621374748089248322   1864254433926636509   \n",
      "\n",
      "                                                 input prediction  \n",
      "6    \"@USER No no è giusto, ce deve sta, la nutri l...        NaN  \n",
      "10   \"#Camera\\nRespinto in commissione un emendamen...        NaN  \n",
      "19   \">Sheryl Sandberg ha fatto simili commenti sul...        NaN  \n",
      "29   \"@USER  @USER Sì ma non è Giusto.\" \"@USER  @US...        NaN  \n",
      "68   \"Ho sentito una ragazza che diceva \"io sono TA...        NaN  \n",
      "86   \"Il caffè al bar, lo pago con moneta contante\\...        NaN  \n",
      "88   \"Mi confermate che 36,1 è da considerare febbr...        NaN  \n",
      "95   \"Una vacanza all'insegna del fascino e della s...        NaN  \n",
      "115  \"Quindi senso comune confermato, chi guida Aud...        NaN  \n",
      "124  \"Fottuto moralismo cristianeggiante\" \"*Fottuto...        NaN  \n",
      "158  \"Mi sembra che ancora non sia stato riportato,...        NaN  \n",
      "169  \"Volevo rinnovare i miei ringraziamenti più si...        NaN  \n",
      "176  \"@USER Che bei coglioni\" \"@USER Un pó da cavallo\"        NaN  \n",
      "178  \"@USER Hai fatto benissimo ? che bella mamma ?...        NaN  \n",
      "Processing model: Minerva-7B-instruct-v1.0_predictions.csv\n",
      "Found 1 NaN predictions in Minerva-7B-instruct-v1.0_predictions.csv for global_actual_labels.csv.\n",
      "     index            post_id_x           reply_id_x               actual  \\\n",
      "181    181  9927703142179117056  9002570000000000000  RHETORICAL QUESTION   \n",
      "\n",
      "               post_id_y           reply_id_y  \\\n",
      "181  9927703142179116661  9002569272707188600   \n",
      "\n",
      "                                                 input prediction  \n",
      "181  \"Eccomi!\\nSono un appassionato di \"wet shaving...        NaN  \n",
      "Processing model: Ministral-8B-Instruct-2410_predictions.csv\n",
      "Found 0 NaN predictions in Ministral-8B-Instruct-2410_predictions.csv for global_actual_labels.csv.\n",
      "Processing model: Qwen2.5-7B-Instruct_predictions.csv\n",
      "Skipping model 'Qwen2.5-7B-Instruct_predictions.csv' as it contains 'qwen'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "model_files = open_files('models_generations')\n",
    "actual_files = open_files('actuals')\n",
    "\n",
    "models = {}\n",
    "for model_file in model_files:\n",
    "    model_name = re.sub(r\"^(fine-tuned-)?|-decoding-\\d+\\.csv$\", \"\", model_file)\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "\n",
    "    if 'qwen' in model_name.lower():\n",
    "        print(f\"Skipping model '{model_name}' as it contains 'qwen'.\")\n",
    "        continue\n",
    "\n",
    "    model = pd.read_csv(os.path.join('models_generations', model_file))\n",
    "\n",
    "    for actual_file in actual_files:\n",
    "        if \"global\" in actual_file:\n",
    "            actual = pd.read_csv(os.path.join('actuals', actual_file))\n",
    "\n",
    "            merged = pd.merge(actual, model, left_on='index', right_index=True, how='left')\n",
    "\n",
    "            # Assicuriamoci che 'input' sia mantenuto\n",
    "            #if 'input' not in merged.columns and 'input' in model.columns:\n",
    "            #    merged['input'] = model['input']\n",
    "\n",
    "            merged_file = f\"{model_name}_merged_output.csv\"\n",
    "            merged.to_csv(merged_file, index=False)\n",
    "\n",
    "            # ritornami i record in cui la prediciton è nan\n",
    "            nan_predictions = merged[merged['prediction'].isna()]\n",
    "            print(f\"Found {len(nan_predictions)} NaN predictions in {model_name} for {actual_file}.\")  \n",
    "            if not nan_predictions.empty:\n",
    "                print(nan_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
